{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generator import Generator\n",
    "import time\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import torch\n",
    "import equinox as eqx\n",
    "# import wandb\n",
    "from hifigan_decoder import HifiDecoder\n",
    "\n",
    "torch_hifigan = HifiDecoder(decoder_input_dim=80).waveform_decoder\n",
    "\n",
    "torch_hifigan.cuda()\n",
    "\n",
    "def to_cuda(x: torch.Tensor) -> torch.Tensor:\n",
    "    if x is None:\n",
    "        return None\n",
    "    if torch.is_tensor(x):\n",
    "        x = x.contiguous()\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda(non_blocking=True)\n",
    "    return x\n",
    "\n",
    "jax_hifigan = Generator(80, 1, key=jax.random.key(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CudaDevice(id=0)]\n",
      "Input Size: 1, JAX Time: 0.042994 s, PyTorch Time: 0.019998 s\n",
      "[CudaDevice(id=0)]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import torch\n",
    "import csv\n",
    "\n",
    "# Assuming jax_dvae and dvae are already defined\n",
    "\n",
    "# Define a range of input sizes\n",
    "input_sizes = [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 512+256]\n",
    "\n",
    "# JIT-compile jax_dvae if not already compiled\n",
    "jax_hifigan = eqx.filter_jit(jax_hifigan)\n",
    "\n",
    "# Open a CSV file to store the results\n",
    "with open('execution_times.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Input Size', 'JAX Execution Time (s)', 'PyTorch Execution Time (s)'])\n",
    "\n",
    "    for size in input_sizes:\n",
    "        # JAX\n",
    "        batch_jax = jnp.ones((size, 80, 1024)).to_device(jax.devices()[0])\n",
    "        \n",
    "        # Warm-up run (to avoid JIT compilation time in the measurement)\n",
    "        for _ in range(0, 10):\n",
    "            _ = eqx.filter_vmap(jax_hifigan)(batch_jax)\n",
    "        \n",
    "        # Measure execution time\n",
    "        start_jax = time.perf_counter()\n",
    "        val_jax = eqx.filter_vmap(jax_hifigan)(batch_jax)\n",
    "        end_jax = time.perf_counter()\n",
    "        jax_time = end_jax - start_jax\n",
    "\n",
    "        # PyTorch\n",
    "        batch_torch = torch.ones((size, 80, 1024)).cuda()\n",
    "        for _ in range(0, 10):\n",
    "            # Warm-up run (to avoid CUDA initialization time in the measurement)\n",
    "            with torch.no_grad():\n",
    "                torch_hifigan.eval()\n",
    "                _ = torch_hifigan(batch_torch)\n",
    "        \n",
    "        # Measure execution time\n",
    "        start_torch = time.perf_counter()\n",
    "        with torch.no_grad():\n",
    "            torch_hifigan.eval()\n",
    "            val_torch = torch_hifigan(batch_torch)\n",
    "        end_torch = time.perf_counter()\n",
    "        torch_time = end_torch - start_torch\n",
    "\n",
    "        # Write the results to the CSV file\n",
    "        writer.writerow([size, jax_time, torch_time])\n",
    "\n",
    "        print(f\"Input Size: {size}, JAX Time: {jax_time:.6f} s, PyTorch Time: {torch_time:.6f} s\")\n",
    "\n",
    "print(\"Done! Results saved to execution_times.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
